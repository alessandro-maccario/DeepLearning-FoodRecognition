{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras\n",
        "!pip install split-folders # install the package to split the images in TRAIN and TEST folders\n",
        "!pip install ann_visualizer # visualize NN architectures"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eWOrFE7O46B1",
        "outputId": "269a0bfd-e141-4d4d-b41e-8394f02ee7b5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikeras in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.7/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=3 in /usr/local/lib/python3.7/dist-packages (from scikeras) (4.13.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (3.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3->scikeras) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: split-folders in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ann_visualizer in /usr/local/lib/python3.7/dist-packages (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sVZbgW2F22Cf"
      },
      "outputs": [],
      "source": [
        "# IMPORT TENSORFLOW/KERAS\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers import Input\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Activation\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.pooling import GlobalMaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# TRANSFER LEARNING\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "# SCIKIT-LEARN/SCIKERAS\n",
        "from sklearn.decomposition import PCA\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import KFold\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# IMPORT OTHER MODULES\n",
        "import os\n",
        "\n",
        "import fnmatch # to count number of image per folder easily\n",
        "import random # to select random images from a folder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import splitfolders # needed to split the images in TRAIN and TEST folders\n",
        "from os import mkdir\n",
        "from pathlib import Path\n",
        "from shutil import copyfile # to import \"copyfile\"\n",
        "import plotly.figure_factory as ff # for printing the heatmap\n",
        "from collections import defaultdict\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as img_mat\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# CV2\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USE THE FOLLOWING RESOURCES\n",
        "\n",
        "**VIDEOS**\n",
        "- https://www.youtube.com/watch?v=kHtToZidh3A\n",
        "\n",
        "GITHUB IMPLEMENTATION\n",
        "- https://github.com/bnsreenu/python_for_microscopists/blob/master/176-multiclass_using_VGG_weights_PCA_NN_RF.py"
      ],
      "metadata": {
        "id": "ZUm6TdrZP7vM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Copy the notebook TRAINING e aggiungici anche questa parte di PCA all'inizio quando carichi tutte le immagini. Poi ci applichi i modelli. \n",
        "APplicare anche il datetime per il clcolo di ogni cella di modello.\n",
        "Applicare anche quanto visto qua:\n",
        "- https://shankarmsy.github.io/posts/pca-sklearn.html\n",
        "- https://towardsdatascience.com/rgb-color-image-compression-using-principal-component-analysis-fce3f48dfdd0\n",
        "- https://towardsdatascience.com/using-pca-to-reduce-number-of-parameters-in-a-neural-network-by-30x-times-fcc737159282\n",
        "\n",
        "Unicamente per mostrare l'immagine finale sotto diverse applicazioni della PCA (con 400, 300, 200, 100, 50, 10 dimensioni), con il codice seguente:"
      ],
      "metadata": {
        "id": "1154dbLuQEn2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualization of the learning curves\n",
        "plt.figure(figsize=(15,6))\n",
        "\n",
        "subplot_index = 1\n",
        "for n_components in [400, 300, 200, 100, 50, 10]:\n",
        "    \n",
        "    plt.subplot(3, 2, subplot_index)\n",
        "    subplot_index = subplot_index + 1\n",
        "\n",
        "    ipca = PCA(n_components).fit(img_reshaped)\n",
        "    transf_img = ipca.transform(img_reshaped)\n",
        "    print(\"transf_img shape is:\", transf_img.shape)\n",
        "\n",
        "    print(\"-----------------------------------\")\n",
        "    print(f\"Explained variances for {n_components}:\", np.sum(ipca.explained_variance_ratio_ ) * 100)\n",
        "    print(\"-----------------------------------\")\n",
        "\n",
        "    # restore the image from the subspace\n",
        "    image_restored = ipca.inverse_transform(transf_img)\n",
        "\n",
        "    # reshape the image to the original array size\n",
        "    image_restored = np.reshape(image_restored, (np.size(img_data, 0),\n",
        "                                                 np.size(img_data, 1),\n",
        "                                                 np.size(img_data, 2)))\n",
        "    \n",
        "    image_restored = image_restored.astype(np.uint8)\n",
        "    # cv2.imwrite(f\"/content/{n_components}.jpg\", cv2.cvtColor(image_restored, cv2.COLOR_RGB2BGR))\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.title('n_components:' + str(n_components))\n",
        "    plt.imshow(image_restored)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Yfvi4ILj6Z1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('/content/100.jpg')"
      ],
      "metadata": {
        "id": "Nuk0PeF66Zzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MJtol1Y36ZtJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}