{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Food Image Classification for the course _Foundations of Deep Learning_.\n",
        "\n",
        "Professors:\n",
        "Paolo Napoletano\n",
        "Marco Buzzelli\n",
        "\n",
        "Tutor:\n",
        "Mirko Agarla\n",
        "\n",
        "## Notebook for Data preprocessing and Data Augmentation"
      ],
      "metadata": {
        "id": "fxNnZukoR0aM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3G490PAURuab",
        "outputId": "0af6083f-5de2-44d2-f9aa-f0bf1f011af1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting split-folders\n",
            "  Downloading split_folders-0.5.1-py3-none-any.whl (8.4 kB)\n",
            "Installing collected packages: split-folders\n",
            "Successfully installed split-folders-0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip install split-folders # install the package to split the images in TRAIN and TEST folders"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT MODULES\n",
        "import os\n",
        "import fnmatch # to count number of image per folder easily\n",
        "import random # to select random images from a folder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import splitfolders # needed to split the images in TRAIN and TEST folders\n",
        "from shutil import copyfile # to import \"copyfile\"\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# CV2\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow "
      ],
      "metadata": {
        "id": "xZKl-Xr0R-0U"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Link Google Drive account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m7V6-hAqSAfa",
        "outputId": "87748ce1-a075-4218-946d-38fafb227f92"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT UTILS.PY\n",
        "\n",
        "# 1.Insert the directory\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food\")\n",
        "\n",
        "# 2.Import your module or file\n",
        "import utils"
      ],
      "metadata": {
        "id": "osbC_ffKSBz8"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTANT\n",
        "# SCALE_PERCENT = 6 # resizing percentage\n",
        "SEED_VALUE = 42\n",
        "num_classes = 9 # number of output classes\n",
        "\n",
        "# PATH TO THE DATA\n",
        "ORIGINAL_DATA = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset\"\n",
        "PREPROCESSED_DATA = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDatasetPreprocessed\"\n",
        "DIR_TRAIN_TEST_DATA = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test' # path contenente i sottoinsiemi di train, test"
      ],
      "metadata": {
        "id": "89TO_j5DSDDk"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Loading the dataset and Data Exploration\n",
        "In this section we will describe the data at hand."
      ],
      "metadata": {
        "id": "fp1ZMzV0SHRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> ## Exploratory Data Analysis (EDA)"
      ],
      "metadata": {
        "id": "50G7Sim5STmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# HOW MANY FOLDERS (CLASSES) DO WE HAVE? WHICH CLASSES DO WE HAVE?\n",
        "lst = os.listdir(ORIGINAL_DATA) # your directory path\n",
        "file_names = lst\n",
        "number_files = len(file_names[1:])\n",
        "print(\"Class names:\", file_names[1:])\n",
        "print(\"Number of classes: \", number_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5VoRu7U9SHjN",
        "outputId": "900c4dcc-8554-4a41-d3aa-af246cf2d2cd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class names: ['french_fries', 'caprese_salad', 'pizza', 'greek_salad', 'sashimi', 'hot_dog', 'caesar_salad', 'hamburger', 'sushi']\n",
            "Number of classes:  9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# COUNT THE NUMBER OF ELEMENTS IN EACH CLASS FOLDERS\n",
        "\n",
        "# FOLDER PATH\n",
        "count = 0\n",
        "hist_dict = {}\n",
        "\n",
        "# ITERATE DIRECTORY\n",
        "for path in os.listdir(ORIGINAL_DATA):\n",
        "    # CHECK IF CURRENT PATH IS A FILE\n",
        "    if os.path.isfile(os.path.join(ORIGINAL_DATA, path)):\n",
        "      count += 0\n",
        "    else:\n",
        "      # IF IS NOT A FILE, IS A DIRECTORY. GET THE FOLDER NAME\n",
        "      number_of_elements_per_folder = len([entry for entry in os.listdir(ORIGINAL_DATA + \"/\" + path)])\n",
        "      print(f\"The folder called {path} has a number of element(s) equal to:\", number_of_elements_per_folder)\n",
        "      count += 1\n",
        "      hist_dict[path] = number_of_elements_per_folder\n",
        "\n",
        "print()\n",
        "print('Number of folders:', count, \"different classes of food.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axw5pwDrSV59",
        "outputId": "edde5afc-0017-475c-f425-5b2032247926"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The folder called french_fries has a number of element(s) equal to: 181\n",
            "The folder called caprese_salad has a number of element(s) equal to: 15\n",
            "The folder called pizza has a number of element(s) equal to: 299\n",
            "The folder called greek_salad has a number of element(s) equal to: 24\n",
            "The folder called sashimi has a number of element(s) equal to: 40\n",
            "The folder called hot_dog has a number of element(s) equal to: 31\n",
            "The folder called caesar_salad has a number of element(s) equal to: 27\n",
            "The folder called hamburger has a number of element(s) equal to: 238\n",
            "The folder called sushi has a number of element(s) equal to: 124\n",
            "\n",
            "Number of folders: 9 different classes of food.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SHOW THE DATASET DISTRIBUTION WITH A HISTOGRAM PLOT\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# CONVERT THE DICT TO DATAFRAME\n",
        "new = pd.DataFrame([hist_dict]).transpose().reset_index()\n",
        "new = new.rename(columns={\"index\": \"food_name\", 0: \"value_count\"})\n",
        "# SORT THE DATAFRAME BASED ON VALUE_COUNT\n",
        "new = new.sort_values(\"value_count\", ascending=False)\n",
        "new\n",
        "\n",
        "# CREATING DATA ON WHICH BAR CHART WILL BE PLOT\n",
        "x_food_name = list(new['food_name'])\n",
        "y_value_count = list(new['value_count'])\n",
        "\n",
        "# CALLING THE FUNCTION TO ADD VALUE LABELS\n",
        "utils.addlabels(x_food_name, y_value_count)\n",
        "plt.xticks(rotation=45)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "TFlWtxgGSXFR",
        "outputId": "61663853-182e-4fe1-92d5-6b5065c80927"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-5b74be0ca7fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# CALLING THE FUNCTION TO ADD VALUE LABELS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddlabels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_food_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_value_count\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'utils' has no attribute 'addlabels'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1080x720 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is clear that this dataset shows an _unbalanced class problem_ that needs to be addressed through _data augmentation_."
      ],
      "metadata": {
        "id": "Uy9HETERScPU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Show some images as example, their original sizes and the format"
      ],
      "metadata": {
        "id": "uk990lP9SeSG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it is visible from the image shape, they are of different sizes but all of them contain the full RGB color spectrum. In order to correctly treat them and feed them inside the CNN it is important that a preprocessing step of resizing them will be applied."
      ],
      "metadata": {
        "id": "owENB9KDSft0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> ### DISPLAY SEVERAL IMAGES AT ONCE\n",
        "Pick some of the images randomly from the dataset, and show them.\n"
      ],
      "metadata": {
        "id": "LoWOfOzeShUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DECIDE THE NUMBER OF IMAGES PER ROW AND COLUMN TO SHOW\n",
        "rows = 3\n",
        "cols = 3\n",
        "\n",
        "# DEFINE SUBPLOTS BASED ON ROWS AND COLUMNS AND FIGSIZE\n",
        "fig, ax = plt.subplots(rows, cols, figsize=(9, 7)) # fig = relative to the figure; ax = relative to the axes.\n",
        "fig.suptitle('Random Image from Each Food Class', fontsize=20) # ADD A TITLE\n",
        "\n",
        "# CREATE AN EMPTY LIST IN ORDER TO ADD ONLY THE DIRECTORY AND NOT THE FILES\n",
        "food_dirs = []\n",
        "\n",
        "# FOR EACH FILE IN ORIGINAL_DATA, CHECK IF IT IS A DIRECTORY AND, IF YES, ADD IT TO THE FOOD_DIRS FOLDER\n",
        "for filename in os.listdir(ORIGINAL_DATA):\n",
        "    if os.path.isdir(os.path.join(ORIGINAL_DATA,filename)):\n",
        "        food_dirs.append(filename)\n",
        "\n",
        "# PRINT THE FINAL LIST\n",
        "# print(food_dirs)\n",
        "\n",
        "# SHOW SOME RANDOM IMAGES FROM THE FOLDERS\n",
        "for i in range(rows):\n",
        "    for j in range(cols):\n",
        "      food_dir = food_dirs[i*cols + j]\n",
        "      all_files = os.listdir(os.path.join(ORIGINAL_DATA, food_dir))\n",
        "      rand_img = np.random.choice(all_files)\n",
        "      img = plt.imread(os.path.join(ORIGINAL_DATA, food_dir, rand_img))\n",
        "      ax[i][j].imshow(img)\n",
        "      \n",
        "      # CREATE COLORS FOR THE BOX AROUND THE TEXT\n",
        "      ec = (0, .6, .1)\n",
        "      fc = (0, .7, .2)\n",
        "      # CREATE THE TEXT ON TOP OF THE IMAGE\n",
        "      ax[i][j].text(0, -20, food_dir, size=10, rotation=0, ha=\"left\", va=\"top\", \n",
        "              bbox=dict(boxstyle=\"round\", ec=ec, fc=fc))\n",
        "      print(f\"The image corresponding to {food_dir} has the shape of:\", img.shape)\n",
        "        \n",
        "# plt.setp(ax, xticks=[], yticks=[]) # do not show the ticks\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])"
      ],
      "metadata": {
        "id": "ScvYoNSJScdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As it is visible from the image shape, they are of different sizes but all of them contain the full RGB color spectrum. In order to correctly treat them and feed them inside the CNN it is important that a preprocessing step of resizing them will be applied."
      ],
      "metadata": {
        "id": "cbgwNLJtSkKI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.DATA PREPROCESSING"
      ],
      "metadata": {
        "id": "VRQARLBrSmMX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Resize all the images\n",
        "\n",
        "#When using the ImageDataGenerator method in keras, the use target_size is used for resizing the images before feed them to the model. So, it is not necessary to resize them in advance!"
      ],
      "metadata": {
        "id": "sOEv74KESnkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE AN EMPTY LIST TO FILL WITH THE CATEGORIES\n",
        "CATEGORIES = []\n",
        "\n",
        "# LOOP THROUGH THE ROOT DIRECTORY, SELECT ONLY THE DIRECTORIES AND SAVE THEIR NAME\n",
        "for filename in os.listdir(ORIGINAL_DATA):\n",
        "    if os.path.isdir(os.path.join(ORIGINAL_DATA,filename)):\n",
        "        CATEGORIES.append(filename)\n",
        "\n",
        "# SHOW THE CATEGORY NAMES\n",
        "CATEGORIES"
      ],
      "metadata": {
        "id": "lbjsrUyoSkVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from os import mkdir\n",
        "from collections import defaultdict\n",
        "# CREATE A DIRECTORY FOR THE PROCESSED IMAGES\n",
        "try:\n",
        "    os.mkdir(PREPROCESSED_DATA)\n",
        "except:\n",
        "    print(\"Folder already found.\")"
      ],
      "metadata": {
        "id": "XV3D3Uy7Spby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RESIZE THE IMAGES AND SAVE THEM\n",
        "\n",
        "# CREATE LISTS TO STORE THE IMAGE SIZE\n",
        "image_size = {}\n",
        "img_width_list = list()\n",
        "img_height_list = list()\n",
        "\n",
        "for i in CATEGORIES:\n",
        "    # print(f'CATEGORY: {i}')\n",
        "    # CREATE A DIRECTORY FOR THE PROCESSED IMAGES\n",
        "    \n",
        "    try:\n",
        "        os.mkdir(os.path.join(PREPROCESSED_DATA,i))\n",
        "    except:\n",
        "        print(\"Folder already found.\")\n",
        "        # pass\n",
        "\n",
        "    path = os.path.join(ORIGINAL_DATA,i)\n",
        "    \n",
        "    for img in os.listdir(path):\n",
        "      if img.endswith(('.png', '.jpg', '.jpeg')):\n",
        "        img_raw = cv2.imread(os.path.join(ORIGINAL_DATA, i, img))\n",
        "        img_width, img_height, img_channel = img_raw.shape # get the size of the image\n",
        "\n",
        "        ##################################################################\n",
        "\n",
        "        # STORE THE WIDTH\n",
        "        img_width_list.append(img_width)\n",
        "        img_width_set = set(img_width_list)\n",
        "\n",
        "        # STORE THE HEIGHT\n",
        "        img_height_list.append(img_height)\n",
        "        img_height_set = set(img_height_list)\n",
        "\n",
        "        ##################################################################\n",
        "\n",
        "        # CHECK IF IMG_WIDTH IS IN THE DICTIONARY. IF NOT ADD IT; IF YES +1\n",
        "        if img_width in image_size:\n",
        "            image_size[img_width] += 1\n",
        "        else:\n",
        "            image_size[img_width] = 1\n",
        "\n",
        "        # CHECK IF IMG_WIDTH IS IN THE DICTIONARY. IF NOT ADD IT; IF YES +1\n",
        "        if img_height in image_size:\n",
        "            image_size[img_height] += 1\n",
        "        else:\n",
        "            image_size[img_height] = 1\n",
        "      else:\n",
        "        continue\n",
        "\n",
        "      # RESIZING\n",
        "      # width1 = int(img_raw.shape[1] * SCALE_PERCENT / 100)\n",
        "      # height1 = int(img_raw.shape[0] * SCALE_PERCENT / 100)\n",
        "      width1 = 224\n",
        "      height1 = 224\n",
        "      dim1 = (width1, height1)\n",
        "      img_resized = cv2.resize(img_raw, dim1, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "      # SAVING THE IMAGES\n",
        "      cv2.imwrite(os.path.join(PREPROCESSED_DATA, i, f\"{img}_RESIZED.jpg\"), img_resized)\n",
        "\n",
        "      # Save Image\n",
        "      print('Saving the image...')"
      ],
      "metadata": {
        "id": "tNy0al7qSq8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GET THE MINIMUM OF WIDTH\n",
        "print(\"Minimum of image width: \", min(set(img_width_list)))\n",
        "\n",
        "# GET THE MAXIMUM OF WIDTH\n",
        "print(\"Maximum of image width: \", max(set(img_width_list)))\n",
        "print()\n",
        "# GET THE MINIMUM OF HEIGHT\n",
        "print(\"Minimum of image height: \", min(set(img_height_list)))\n",
        "\n",
        "# GET THE MAXIMUM OF HEIGHT\n",
        "print(\"Maximum of image height: \", max(set(img_height_list)))"
      ],
      "metadata": {
        "id": "4-l9UBoFSq5f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PLOT AN HISTOGRAM OF IMAGE SIZES\n",
        "plt.figure(figsize=(10,8))\n",
        "plt.bar(list(image_size.keys()), image_size.values(), color='b')\n",
        "plt.xlim((0,1000))\n",
        "plt.ylim((0,40))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WlUk5IvWSq3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Splitting"
      ],
      "metadata": {
        "id": "CtpUafFTSwnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE A DIRECTORY FOR THE SPLITTING\n",
        "try:\n",
        "    os.mkdir(DIR_TRAIN_TEST_DATA)\n",
        "except:\n",
        "    print(\"Folder already found.\")"
      ],
      "metadata": {
        "id": "tRHVqBCVSq1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SPLIT THE IMAGE IN TRAIN AND TEST SETS. 65% TRAIN DATA AND 35% TEST DATA.\n",
        "splitfolders.ratio(PREPROCESSED_DATA,\n",
        "                   output= DIR_TRAIN_TEST_DATA,\n",
        "                   seed = SEED_VALUE,\n",
        "                   ratio = (.65, .20, .15)) # training, validation, testing"
      ],
      "metadata": {
        "id": "Il52RPEtSqyy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Data Augmentation on the train set\n",
        "\n",
        "In this section we will apply different techniques in order to create additional images to be fed, later, into the model.\n",
        "Why _Data Augmentation_? (INSERT DESCRIPTION)"
      ],
      "metadata": {
        "id": "XbyCCMhSS13_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK AGAIN THE NUMBER OF IMAGES FOR EACH CLASSES\n",
        "# COUNT THE NUMBER OF ELEMENTS IN EACH CLASS FOLDERS\n",
        "\n",
        "# COUNT IMAGES AND CREATE A DICT\n",
        "count_processed = 0\n",
        "hist_dict_processed = {}\n",
        "\n",
        "# ITERATE DIRECTORY\n",
        "for path in os.listdir(DIR_TRAIN_TEST_DATA):\n",
        "  if path == \"train\":\n",
        "\n",
        "    print(path)\n",
        "    for categories in os.listdir(os.path.join(DIR_TRAIN_TEST_DATA, path)):\n",
        "      print(\"--\", categories)\n",
        "\n",
        "      for images in os.listdir(os.path.join(DIR_TRAIN_TEST_DATA, path, categories)):\n",
        "\n",
        "        # CHECK IF CURRENT PATH IS A FILE\n",
        "        if os.path.isfile(os.path.join(DIR_TRAIN_TEST_DATA, path, categories)):\n",
        "          count_processed += 0\n",
        "        else:\n",
        "          # IF IS NOT A FILE, IS A DIRECTORY. GET THE FOLDER NAME\n",
        "          number_of_elements_per_folder = len([entry for entry in os.listdir(DIR_TRAIN_TEST_DATA + \"/\" + path + \"/\" + categories)])\n",
        "          # print(f\"The folder called {path} has a number of element(s) equal to:\", number_of_elements_per_folder)\n",
        "          count_processed += 1\n",
        "          hist_dict_processed[categories] = number_of_elements_per_folder\n",
        "  else:\n",
        "    break\n",
        "\n",
        "print()\n",
        "# print('Number of folders:', count_processed, \"different classes of food.\")"
      ],
      "metadata": {
        "id": "hKp1bPzASqwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHOW THE DATASET DISTRIBUTION WITH A HISTOGRAM PLOT ONLY FOR THE TRAINING SET\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# CONVERT THE DICT TO DATAFRAME\n",
        "new_processed = pd.DataFrame([hist_dict_processed]).transpose().reset_index()\n",
        "new_processed = new_processed.rename(columns={\"index\": \"food_name\", 0: \"value_count\"})\n",
        "\n",
        "# SORT THE DATAFRAME BASED ON VALUE_COUNT\n",
        "new_processed = new_processed.sort_values(\"value_count\", ascending=False)\n",
        "new_processed\n",
        "\n",
        "# PLOT THE BAR AND THE TICKS\n",
        "plt.bar(new_processed['food_name'], new_processed['value_count'], color='g')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# CREATING DATA ON WHICH BAR CHART WILL BE PLOT\n",
        "x_food_name = list(new_processed['food_name'])\n",
        "y_value_count = list(new_processed['value_count'])\n",
        "\n",
        "# CALLING THE FUNCTION TO ADD VALUE LABELS\n",
        "utils.addlabels(x_food_name, y_value_count)"
      ],
      "metadata": {
        "id": "Aa7crVAXS3lg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is still visible that the training set has imbalance classes, a problem that has to be faced before creating the Convolutional Neural Network model."
      ],
      "metadata": {
        "id": "f6ktzjP1S6bk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DATA AUGMENTATION\n",
        "\n",
        "# COUNT IMAGES AND CREATE A DICT\n",
        "count_images = 0\n",
        "\n",
        "# ITERATE DIRECTORY\n",
        "for path in os.listdir(DIR_TRAIN_TEST_DATA):\n",
        "  if path == \"train\":\n",
        "\n",
        "    print(path)\n",
        "    for categories in os.listdir(os.path.join(DIR_TRAIN_TEST_DATA, path)):\n",
        "      print(\"--\", categories)\n",
        "      # USE https://docs.python.org/3/library/fnmatch.html TO CHECK THE SIZE OF EACH FOLDER\n",
        "      category_size = len(fnmatch.filter(os.listdir(os.path.join(DIR_TRAIN_TEST_DATA, path, categories)), '*.jpg'))\n",
        "\n",
        "      while category_size < 200:\n",
        "        \n",
        "\n",
        "        # PATH TO THE IMAGES\n",
        "        category_path_folder = fnmatch.filter(os.listdir(os.path.join(DIR_TRAIN_TEST_DATA, path, categories)), '*.jpg')\n",
        "        # print(DIR_TRAIN_TEST_DATA)\n",
        "\n",
        "        # LOAD A RANDOM IMAGE AND READ IT\n",
        "        random_image = random.choice(category_path_folder)\n",
        "        image = cv2.imread(os.path.join(DIR_TRAIN_TEST_DATA, path, categories, random_image))\n",
        "\n",
        "        # PERFORM DATA AUGMENTATION\n",
        "        # -------------------------\n",
        "        # HORIZONTAL FLIP\n",
        "        img_horiz_flipped = utils.horizontal_flip(image, True)\n",
        "        # VERTICAL FLIP\n",
        "        img_vertical_flipped = utils.vertical_flip(image, True)\n",
        "        # BRIGHTNESS\n",
        "        img_brightness = utils.brightness(image, 0.5, 1.3)\n",
        "        # CHANNEL SHIFT\n",
        "        img_hue_image = utils.hue_image(image, 5)\n",
        "        \n",
        "        # SHOW THE IMAGE\n",
        "        # cv2_imshow(img_horiz_flipped)\n",
        "\n",
        "        # SAVING THE IMAGES\n",
        "        cv2.imwrite(os.path.join(DIR_TRAIN_TEST_DATA, path, categories, f\"{random_image}_horiz_flipped.jpg\"), img_horiz_flipped)\n",
        "        cv2.imwrite(os.path.join(DIR_TRAIN_TEST_DATA, path, categories, f\"{random_image}_vertical_flipped.jpg\"), img_vertical_flipped)\n",
        "        cv2.imwrite(os.path.join(DIR_TRAIN_TEST_DATA, path, categories, f\"{random_image}_vertical_flipped.jpg\"), img_brightness)\n",
        "        cv2.imwrite(os.path.join(DIR_TRAIN_TEST_DATA, path, categories, f\"{random_image}_vertical_flipped.jpg\"), img_hue_image)\n",
        "        # print(os.path.join(DIR_TRAIN_TEST_DATA, path, categories, f\"{random_image}_horiz_flipped.jpg\"), img_horiz_flipped)\n",
        "\n",
        "        # WHAT IS THE CURRENT SIZE OF THE FOLDER?\n",
        "        category_size = len(fnmatch.filter(os.listdir(os.path.join(DIR_TRAIN_TEST_DATA, path, categories)), '*.jpg'))\n",
        "        print(\"Category size is (continue until reached 1000 images in each folder):\", category_size)\n",
        "\n",
        "      else:\n",
        "        # EXIT FROM THIS CATEGORY DIRECTORY IF THE NUMBER OF IMAGES INSIDE IS MORE THAN 200\n",
        "        continue\n",
        "\n",
        "  else:\n",
        "    break"
      ],
      "metadata": {
        "id": "xYqh-OJwS6lj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK SIZE OF FOLDERS\n",
        "print(\"Size of the folder caesar_salad: \",  len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/caesar_salad\"), '*.jpg')))\n",
        "print(\"Size of the folder caprese_salad: \", len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/caprese_salad\"), '*.jpg')))\n",
        "print(\"Size of the folder french_fries: \",  len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/french_fries\"), '*.jpg')))\n",
        "print(\"Size of the folder greek_salad: \",   len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/greek_salad\"), '*.jpg')))\n",
        "print(\"Size of the folder hamburger: \",     len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/hamburger\"), '*.jpg')))\n",
        "print(\"Size of the folder hot_dog: \",     len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/hot_dog\"), '*.jpg')))\n",
        "print(\"Size of the folder pizza: \",     len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/pizza\"), '*.jpg')))\n",
        "print(\"Size of the folder sashimi: \",     len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/sashimi\"), '*.jpg')))\n",
        "print(\"Size of the folder sushi: \",     len(fnmatch.filter(os.listdir(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/sushi\"), '*.jpg')))"
      ],
      "metadata": {
        "id": "Kpgtl13uTBCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CHECK AGAIN THE NUMBER OF IMAGES FOR EACH CLASSES\n",
        "# COUNT THE NUMBER OF ELEMENTS IN EACH CLASS FOLDERS\n",
        "\n",
        "# COUNT IMAGES AND CREATE A DICT\n",
        "count_processed = 0\n",
        "hist_dict_processed = {}\n",
        "\n",
        "# ITERATE DIRECTORY\n",
        "for path in os.listdir(DIR_TRAIN_TEST_DATA):\n",
        "  if path == \"train\":\n",
        "\n",
        "    print(path)\n",
        "    for categories in os.listdir(os.path.join(DIR_TRAIN_TEST_DATA, path)):\n",
        "      print(\"--\", categories)\n",
        "\n",
        "      for images in os.listdir(os.path.join(DIR_TRAIN_TEST_DATA, path, categories)):\n",
        "\n",
        "        # CHECK IF CURRENT PATH IS A FILE\n",
        "        if os.path.isfile(os.path.join(DIR_TRAIN_TEST_DATA, path, categories)):\n",
        "          count_processed += 0\n",
        "        else:\n",
        "          # IF IS NOT A FILE, IS A DIRECTORY. GET THE FOLDER NAME\n",
        "          number_of_elements_per_folder = len([entry for entry in os.listdir(DIR_TRAIN_TEST_DATA + \"/\" + path + \"/\" + categories)])\n",
        "          # print(f\"The folder called {path} has a number of element(s) equal to:\", number_of_elements_per_folder)\n",
        "          count_processed += 1\n",
        "          hist_dict_processed[categories] = number_of_elements_per_folder\n",
        "  else:\n",
        "    break\n",
        "\n",
        "print()\n",
        "# print('Number of folders:', count_processed, \"different classes of food.\")"
      ],
      "metadata": {
        "id": "34o9pi8FTC01"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHOW THE DATASET DISTRIBUTION WITH A HISTOGRAM PLOT ONLY FOR THE TRAINING SET\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# CONVERT THE DICT TO DATAFRAME\n",
        "new_processed = pd.DataFrame([hist_dict_processed]).transpose().reset_index()\n",
        "new_processed = new_processed.rename(columns={\"index\": \"food_name\", 0: \"value_count\"})\n",
        "\n",
        "# SORT THE DATAFRAME BASED ON VALUE_COUNT\n",
        "new_processed = new_processed.sort_values(\"value_count\", ascending=False)\n",
        "new_processed\n",
        "\n",
        "# PLOT THE BAR AND THE TICKS\n",
        "plt.bar(new_processed['food_name'], new_processed['value_count'], color='g')\n",
        "plt.xticks(rotation=45)\n",
        "\n",
        "# CREATING DATA ON WHICH BAR CHART WILL BE PLOT\n",
        "x_food_name = list(new_processed['food_name'])\n",
        "y_value_count = list(new_processed['value_count'])\n",
        "\n",
        "# CALLING THE FUNCTION TO ADD VALUE LABELS\n",
        "utils.addlabels(x_food_name, y_value_count)"
      ],
      "metadata": {
        "id": "v4GtQHJxTEs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Now all the folders present a number of elements of 200 elements, solving the class unbalanced problem.\n",
        "\n",
        "### Example of augmented images: in order to demonstrate how the data augmentation works, the following picture shows the application of brightness to a single image before applying it to multiple images in the dataset."
      ],
      "metadata": {
        "id": "0R_9JevwgT2p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SHOW THE SIZE OF THE IMAGE: THE IMAGE HAS BEEN RESIZED\n",
        "french_fries_shape = cv2.imread(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDatasetPreprocessed/french_fries/20160725_123734.jpg_RESIZED.jpg\")\n",
        "french_fries_shape.shape"
      ],
      "metadata": {
        "id": "7RRJepDJgb5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "french_fries_brightness = cv2.imread(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/french_fries/cropfries46.jpg\")\n",
        "cv2_imshow(french_fries_brightness)"
      ],
      "metadata": {
        "id": "WicJ2tAGgSkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# THE BRIGHTNESS FUNCTION RELIES ON A RANDOM CHOICE OF THE LOW AND HIGH VALUES.\n",
        "# THEREFORE, EACH ITERATION CAN BE DIFFERENT FROM THE PREVIOUS ONE.\n",
        "img_brightness = brightness(french_fries_brightness, 0.5, 1.3)\n",
        "cv2_imshow(img_brightness)"
      ],
      "metadata": {
        "id": "Jhp9LhfTgYYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_hue_image = hue_image(french_fries_brightness, 5)\n",
        "cv2_imshow(img_hue_image)"
      ],
      "metadata": {
        "id": "e114i-RPgZem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SHOW THE RGB HISTOGRAM\n",
        "\n",
        "# SET THE SIZE OF THE PICTURE\n",
        "plt.figure(figsize=(10, 8)) \n",
        "\n",
        "# SETTING VALUES TO ROWS, COLUMN AND COLOR VARIABLE\n",
        "# rows = 2\n",
        "# columns = 2\n",
        "colors = ('blue','green','red')\n",
        "label = (\"Blue\", \"Green\", \"Red\")\n",
        "\n",
        "# the container holding the two Axes have already been unpacked\n",
        "# useful if just few Axes have been created\n",
        "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 8)) \n",
        "\n",
        "# FIRST PLOT ON THE LEFT\n",
        "for count,color in enumerate(colors):\n",
        "    histogram = cv2.calcHist(images = [french_fries_brightness], channels = [count], mask = None, histSize = [256], ranges = [0,256])\n",
        "    # NORMALIZE IT\n",
        "    histogram /= histogram.sum()\n",
        "    ax1.plot(histogram,color = color, label=label[count]+str(\" Pixels\"))\n",
        "\n",
        "ax1.set_title('Histogram Showing Number Of Pixels Belonging To Respective Pixel Intensity')\n",
        "ax1.set_xlabel('Pixel Intensity - first plot')\n",
        "ax1.set_ylabel('% Of Pixels - first plot')\n",
        "ax1.legend(numpoints = 1, loc = \"best\")\n",
        "\n",
        "for count,color in enumerate(colors):\n",
        "    histogram = cv2.calcHist(images = [img_brightness], channels = [count], mask = None, histSize = [256], ranges = [0,256])\n",
        "    # NORMALIZE IT\n",
        "    histogram /= histogram.sum()\n",
        "    ax2.plot(histogram,color = color, label=label[count]+str(\" Pixels\"))\n",
        "\n",
        "ax2.set_title('Histogram Showing Number Of Pixels Belonging To Respective Pixel Intensity')\n",
        "ax2.set_xlabel('Pixel Intensity - second plot')\n",
        "ax2.set_ylabel('% Of Pixels - second plot')\n",
        "ax2.legend(numpoints = 1, loc = \"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5LOReDeFga5T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A histogram represents the distribution of pixel intensities (whether color or grayscale) in an image. It can be visualized as a graph (or plot) that gives a high-level intuition of the intensity (pixel value) distribution. We are going to assume a RGB color space in this example, so these pixel values will be in the range of 0 to 255.\n",
        "Each of the red, green and blue light levels is encoded as a number in the range 0.. 255, with 0 meaning zero light and 255 meaning maximum light. So for example (red=255, green=100, blue=0) is a color where red is maximum, green is medium, and blue is not present at all, resulting in a shade of orange.\n",
        "\n",
        "Furthermore, the bins (0-255) are plotted on the x-axis. And the y-axis counts the number of pixels in each bin.\n",
        "\n",
        "The majority of the pixels fall in the range of roughly 5 to 60: this implies that there are a lot of \"black\" and very few \"white\" pixels in the image.\n",
        "In the right figure we can see that a bigger amount of darker pixel are created, so we can say that the brightness function created a darker image than the original one."
      ],
      "metadata": {
        "id": "AugXlOlTgddg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check this out for data augmentation:\n",
        "- https://towardsdatascience.com/complete-image-augmentation-in-opencv-31a6b02694f5\n",
        "\n",
        "Prossimi passi:\n",
        "- creare un for loop che vada a raccogliere tutte le immagini per ciascuna cartella SOLAMENTE PER IL TRAINING SET\n",
        "- se la numerosità delle immagini è < 200, allora applica trasformazioni, salva nuove immagini trasformate e se si raggiungono le 200 immagini, procedi con la cartella successiva.\n",
        "- se tutto ciò funziona, usa poi la data augmentation con ImageDataGenerator per creare un numero maggiore di immagini ma solo nella fase di modellazione! (check this out: https://stackoverflow.com/questions/51748514/does-imagedatagenerator-add-more-images-to-my-dataset; https://www.researchgate.net/post/How-many-images-does-Imagedatagenerator-generate-in-deep-learning#:~:text=Then%20the%20%22ImageDataGenerator%22%20will%20produce,there%20will%20be%20100%20iterations.)"
      ],
      "metadata": {
        "id": "3qt6qh1ogfuW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Q8YOeWn6gSie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sk5uAjZ_gSgU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}