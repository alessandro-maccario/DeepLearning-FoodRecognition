{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 3 TESTING NOTEBOOK - TEST 2"
      ],
      "metadata": {
        "id": "jYo52JpkA7vQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "So97mTDsA6f2",
        "outputId": "f4cc9ae4-b303-440a-8f2e-a9f32a3c1cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikeras\n",
            "  Downloading scikeras-0.10.0-py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from scikeras) (1.0.2)\n",
            "Requirement already satisfied: packaging>=0.21 in /usr/local/lib/python3.8/dist-packages (from scikeras) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging>=0.21->scikeras) (3.0.9)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.7.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.14.6 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.21.6)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=1.0.0->scikeras) (1.2.0)\n",
            "Installing collected packages: scikeras\n",
            "Successfully installed scikeras-0.10.0\n"
          ]
        }
      ],
      "source": [
        "# INSTALL SCIKERAS PACKAGES\n",
        "!pip install scikeras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT TENSORFLOW/KERAS\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
        "\n",
        "from keras.layers.core import Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# SCIKIT-LEARN/SCIKERAS\n",
        "from sklearn import preprocessing\n",
        "import sklearn.metrics as metrics\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# IMPORT OTHER MODULES\n",
        "import os\n",
        "import os.path\n",
        "import sys\n",
        "import glob\n",
        "import datetime\n",
        "from pathlib import Path\n",
        "\n",
        "import fnmatch # to count number of image per folder easily\n",
        "import random # to select random images from a folder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from os import mkdir\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from shutil import copyfile # to import \"copyfile\"\n",
        "from numpy.random import seed\n",
        "import matplotlib.image as img_mat\n",
        "import plotly.figure_factory as ff # for printing the heatmap\n",
        "from collections import defaultdict\n",
        "from matplotlib import pyplot as plt\n",
        "from IPython.display import Javascript\n",
        "\n",
        "# CV2\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow "
      ],
      "metadata": {
        "id": "G0i-P8WjBGSM"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Link Google Drive account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtkiYvd8W-4v",
        "outputId": "f4943343-c91f-48ee-ae0a-736de4d5f7bc"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTANT\n",
        "SEED_VALUE = 42\n",
        "num_classes = 9 # number of output classes\n",
        "batch_size = 16\n",
        "SIZE = 224  #Resize images --> https://www.researchgate.net/post/Which_Image_resolution_should_I_use_for_training_for_deep_neural_network#:~:text=So%20the%20rule%20of%20thumb,for%20something%20smaller%20and%20easier.\n",
        "\n",
        "# PATH TO THE DATA\n",
        "ORIGINAL_DATA = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset\"\n",
        "base_path_test = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/test/'\n",
        "DIR_TEST_DATA = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/test/*' # path contenente i sottoinsiemi di train, test"
      ],
      "metadata": {
        "id": "64vY3SgfaUk9"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # # Capture training data and labels into respective lists\n",
        "# # train_images = []\n",
        "# # train_labels = [] \n",
        "\n",
        "# # # GET THE LABELS\n",
        "# # for directory_path in glob.glob(DIR_TRAIN_DATA):\n",
        "# #     tr_label = directory_path.split(\"/\")[-1]\n",
        "# #     print(tr_label)\n",
        "# #     # GET THE IMAGES\n",
        "# #     for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "# #         # print(img_path)\n",
        "# #         img = cv2.imread(img_path, cv2.IMREAD_COLOR)       \n",
        "# #         img = cv2.resize(img, (SIZE, SIZE))\n",
        "# #         img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "# #         train_images.append(img)\n",
        "# #         train_labels.append(tr_label)\n",
        "\n",
        "# # # CONVERT LISTS TO ARRAYS\n",
        "# # train_images = np.array(train_images)\n",
        "# # train_labels = np.array(train_labels)\n",
        "\n",
        "# ################################################################\n",
        "# # CAPTURE TEST/VALIDATION DATA AND LABELS INTO RESPECTIVE LISTS\n",
        "\n",
        "# test_images = []\n",
        "# test_labels = [] \n",
        "# for directory_path in glob.glob(DIR_TEST_DATA):\n",
        "#     tt_label = directory_path.split(\"/\")[-1]\n",
        "#     for img_path in glob.glob(os.path.join(directory_path, \"*.jpg\")):\n",
        "#         img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "#         img = cv2.resize(img, (SIZE, SIZE))\n",
        "#         img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "#         test_images.append(img)\n",
        "#         test_labels.append(tt_label)\n",
        "\n",
        "# #Convert lists to arrays                \n",
        "# test_images = np.array(test_images)\n",
        "# test_labels = np.array(test_labels)"
      ],
      "metadata": {
        "id": "0I8d-Qe4aXpE"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def prep_fn(img):\n",
        "#     img = img.astype(np.float32) / 255.0\n",
        "#     img = (img - 0.5) * 2\n",
        "#     return img"
      ],
      "metadata": {
        "id": "BtGd50rNtz2G"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess_input_mobilenetV2 = tf.keras.applications.mobilenet_v2.preprocess_input"
      ],
      "metadata": {
        "id": "XaQSpUZGLBsq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_path_train = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/'\n",
        "\n",
        "# train_datagen_mnetv2 = ImageDataGenerator(preprocessing_function = preprocess_input_mobilenetV2)\n",
        "train_datagen_mnetv2 = ImageDataGenerator()\n",
        "\n",
        "train_generator_mnetv2 = train_datagen_mnetv2.flow_from_directory(\n",
        "    base_path_train,\n",
        "    target_size=(224, 224),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=16,\n",
        "    shuffle=True,\n",
        "    class_mode=\"categorical\",\n",
        "    seed = SEED_VALUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVrNTAl0xE32",
        "outputId": "f1f9fe81-aa5d-434c-9679-ee9d5dfc7a66"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1803 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_datagen_mnetv2 = ImageDataGenerator() # rescale=1./255\n",
        "# test_datagen_mnetv2 = ImageDataGenerator(preprocessing_function = preprocess_input_mobilenetV2) \n",
        "test_datagen_mnetv2 = ImageDataGenerator()\n",
        "\n",
        "# TOGLIERE: USARE SOLO NEL NOTEBOOK DI TEST!\n",
        "test_generator = test_datagen_mnetv2.flow_from_directory(\n",
        "    base_path_test,\n",
        "    target_size=(SIZE, SIZE), # target_size=(224,224),\n",
        "    color_mode=\"rgb\",\n",
        "    batch_size=1,\n",
        "    # batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    # class_mode=\"categorical\",\n",
        "    class_mode=None,\n",
        "    seed = SEED_VALUE)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe7cOs5jawEW",
        "outputId": "25b201b2-ef30-4269-b644-7afc4d613fb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 155 images belonging to 9 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ground_truth_dict = test_generator.class_indices\n",
        "ground_truth_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2-i8hPtDatzQ",
        "outputId": "d444ce0f-0c78-45aa-e425-8dd1c9db7606"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'caesar_salad': 0,\n",
              " 'caprese_salad': 1,\n",
              " 'french_fries': 2,\n",
              " 'greek_salad': 3,\n",
              " 'hamburger': 4,\n",
              " 'hot_dog': 5,\n",
              " 'pizza': 6,\n",
              " 'sashimi': 7,\n",
              " 'sushi': 8}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD SAVED MODEL AND GET PATH FOR AN IMAGE\n",
        "best_model = tf.keras.models.load_model(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/saved_models/model_mobilenetV2.h5\") "
      ],
      "metadata": {
        "id": "fBD6iJb7szNz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
        "\n",
        "# test_generator.reset() # https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
        "\n",
        "pred = best_model.predict(test_generator, \n",
        "                          steps=STEP_SIZE_TEST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNu8CkUVsu1N",
        "outputId": "991bb598-abc7-43d9-f05c-af18f982cbf0"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "155/155 [==============================] - 23s 138ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CG7Pc8Essuy3",
        "outputId": "67efe6ab-ce7d-4165-fb70-8d78428cb52f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "155"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_indices=np.argmax(pred,axis=1)"
      ],
      "metadata": {
        "id": "mPa5q_eQsuwr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_class_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1c3H6X5suug",
        "outputId": "eb02d669-2033-4d06-bfb0-d706d3831e7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 3, 4, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 3, 2, 2,\n",
              "       2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2,\n",
              "       3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 8, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 3, 4, 2, 2, 2, 2, 4, 2, 2, 3, 3,\n",
              "       2, 2, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 3,\n",
              "       4])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = (train_generator_mnetv2.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]"
      ],
      "metadata": {
        "id": "s8y4Cdu8tpYK"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator.filenames"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDLzhM0zzSXG",
        "outputId": "8b90ea93-c7a4-401e-8859-7218644b2f7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['caesar_salad/crop_caesar1.jpg_RESIZED.jpg',\n",
              " 'caesar_salad/crop_caesar66.jpg_RESIZED.jpg',\n",
              " 'caesar_salad/smaller_salad (100).jpg_RESIZED.jpg',\n",
              " 'caesar_salad/smaller_salad (101).jpg_RESIZED.jpg',\n",
              " 'caesar_salad/smaller_salad (7).jpg_RESIZED.jpg',\n",
              " 'caprese_salad/crop_caesar7.jpg_RESIZED.jpg',\n",
              " 'caprese_salad/smaller_salad (11).jpg_RESIZED.jpg',\n",
              " 'caprese_salad/smaller_salad (20).jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries13.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries14.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries15.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries28.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries29.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries31.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries33.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries4.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries53.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries58.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries59.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries6.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries61.jpg_RESIZED.jpg',\n",
              " 'french_fries/cropfries64.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_102.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_103.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_159.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_16.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_167.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_26.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_47.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_50.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_57.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_58.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_60.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_71.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_90.jpg_RESIZED.jpg',\n",
              " 'french_fries/french_fries_97.jpg_RESIZED.jpg',\n",
              " 'greek_salad/crop_caesar3.jpg_RESIZED.jpg',\n",
              " 'greek_salad/crop_caesar8.jpg_RESIZED.jpg',\n",
              " 'greek_salad/smaller_salad (120).jpg_RESIZED.jpg',\n",
              " 'greek_salad/smaller_salad (121).jpg_RESIZED.jpg',\n",
              " 'greek_salad/smaller_salad (168).jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger10.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger15.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger16.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger17.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger3.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger30.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger33.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger35.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger41.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger55.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger6.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger60.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger61.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger63.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger66.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger73.jpg_RESIZED.jpg',\n",
              " 'hamburger/cropburger74.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_505.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_506.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_519.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_537.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_562.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_566.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_573.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_584.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_587.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_600.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_603.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_610.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_617.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_627.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_632.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_633.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_642.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_679.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_688.jpg_RESIZED.jpg',\n",
              " 'hamburger/hamburger_689.jpg_RESIZED.jpg',\n",
              " 'hot_dog/20160711_1214411.jpg_RESIZED.jpg',\n",
              " 'hot_dog/20160712_1210001.jpg_RESIZED.jpg',\n",
              " 'hot_dog/20160715_1239322.jpg_RESIZED.jpg',\n",
              " 'hot_dog/IMG_20150722_121408093_HDR.jpg_RESIZED.jpg',\n",
              " 'hot_dog/IMG_20160702_1922062443.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza12.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza20.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza21.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza23.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza24.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza3.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza46.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza5.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza52.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza54.jpg_RESIZED.jpg',\n",
              " 'pizza/crop_pizza6.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_174.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_181.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_192.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_200.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_203.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_227.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_237.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_238.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_239.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_241.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_247.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_253.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_267.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_272.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_274.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_282.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_292.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_303.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_305.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_307.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_314.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_324.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_325.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_343.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_345.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_347.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_363.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_371.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_412.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_435.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_438.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_445.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_448.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_450.jpg_RESIZED.jpg',\n",
              " 'pizza/pizza_451.jpg_RESIZED.jpg',\n",
              " 'sashimi/crop__sashimi10.jpg_RESIZED.jpg',\n",
              " 'sashimi/crop__sashimi16.jpg_RESIZED.jpg',\n",
              " 'sashimi/crop__sashimi17.jpg_RESIZED.jpg',\n",
              " 'sashimi/crop__sashimi22.jpg_RESIZED.jpg',\n",
              " 'sashimi/crop__sashimi23.jpg_RESIZED.jpg',\n",
              " 'sashimi/crop__sashimi25.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi12.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi13.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi2.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi21.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi22.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi25.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi34.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi35.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi38.jpg_RESIZED.jpg',\n",
              " 'sushi/crop__sushi41.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_110.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_14.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_157.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_164.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_2.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_31.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_67.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_72.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_89.jpg_RESIZED.jpg',\n",
              " 'sushi/sushi_94.jpg_RESIZED.jpg']"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filenames=test_generator.filenames\n",
        "# filenames=train_generator_mnetv2.filenames\n",
        "results=pd.DataFrame({\"Filename\":filenames,\n",
        "                      \"Predictions\":predictions})\n",
        "results.to_csv(\"results.csv\",index=False)"
      ],
      "metadata": {
        "id": "oY0Rb586tyf5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "51MolU6QtpSc"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-------------------"
      ],
      "metadata": {
        "id": "GRjQqhgWT7OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use Path object to grab all the images in a folder\n",
        "caesar_salad_dir  = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/caesar_salad\")\n",
        "caprese_salad_dir = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/caprese_salad\")\n",
        "french_fries_dir  = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/french_fries\")\n",
        "greek_salad_dir   = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/greek_salad\")\n",
        "hamburger_dir     = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/hamburger\")\n",
        "hot_dog_dir       = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/hot_dog\")\n",
        "pizza_dir         = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/pizza\")\n",
        "sashimi_dir       = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/sashimi\")\n",
        "sushi_dir         = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset/sushi\")"
      ],
      "metadata": {
        "id": "9e7Z0dtZ0YCu"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_df(image_dir, label): \n",
        "  # get all the filepath. Convert to string for using flow_from_dataframe later\n",
        "  filepaths = pd.Series(list(image_dir.glob(r'*.jpg')), name=\"Filepath\").astype(str) # name: give the Series a name\n",
        "  # labels\n",
        "  labels = pd.Series(label, name=\"Label\", index=filepaths.index)\n",
        "  # concatenate two series as a dataframe\n",
        "  df = pd.concat([filepaths, labels], axis=1)\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "QPIpS4DsT6nH"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "caesar_salad_df  = generate_df(caesar_salad_dir,  label=\"CAESAR_SALAD\")\n",
        "caprese_salad_df = generate_df(caprese_salad_dir, label=\"CAPRESE_SALAD\")\n",
        "french_fries_df  = generate_df(french_fries_dir,  label=\"FRENCH_FRIES\")\n",
        "greek_salad_df   = generate_df(greek_salad_dir,   label=\"GREEK_SALAD\")\n",
        "hamburger_df     = generate_df(hamburger_dir,     label=\"HAMBURGER\")\n",
        "hot_dog_df       = generate_df(hot_dog_dir,       label=\"HOT_DOG\")\n",
        "pizza_df         = generate_df(pizza_dir,         label=\"PIZZA\")\n",
        "sashimi_df       = generate_df(sashimi_dir,       label=\"SASHIMI\")\n",
        "caesar_salad_df  = generate_df(caesar_salad_dir,  label=\"CAESAR_SALAD\")\n",
        "sushi_df         = generate_df(sushi_dir,         label=\"SUSHI\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2rSf5XrT6ka",
        "outputId": "4f327c1c-1d04-4204-dfcd-2735f943e1ea"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-36-3ba43c3058a0>:3: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
            "  filepaths = pd.Series(list(image_dir.glob(r'*.jpg')), name=\"Filepath\").astype(str) # name: give the Series a name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_df = pd.concat([caesar_salad_df,\n",
        "                    caprese_salad_df,\n",
        "                    french_fries_df,\n",
        "                    greek_salad_df,\n",
        "                    hamburger_df,\n",
        "                    hot_dog_df,\n",
        "                    pizza_df,\n",
        "                    sashimi_df,\n",
        "                    caesar_salad_df,\n",
        "                    sushi_df], \n",
        "                   axis=0).sample(frac=1.0, random_state=1).reset_index(drop=True) \n",
        "                   # sample and shuffle at the same time and reset index to have the correct values.\n",
        "                   # drop the previous index so you do not have another column for that.\n",
        "\n",
        "# problems:\n",
        "#   - indeces are wrong\n",
        "#   - the label are on top of each other and not shuffled\n",
        "all_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        },
        "id": "8YWr0EDIT6gj",
        "outputId": "9190436d-9934-44b0-da7e-431b7635e75f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Filepath, Label]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b7d25ee-b47a-4dba-826b-1820ed0b7417\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filepath</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b7d25ee-b47a-4dba-826b-1820ed0b7417')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b7d25ee-b47a-4dba-826b-1820ed0b7417 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b7d25ee-b47a-4dba-826b-1820ed0b7417');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this helps us to deal with memory issues to train a large dataset. Loading and training and recycling the memory at\n",
        "# the same time. You can add a Data Augmentation process but it is not mandatory.\n",
        "# But we can rescale the images so the pixel data are coming in as values between 0 and 1.\n",
        "# The standard encoding for pixels values are in RGB scale between 0 and 255 (255 maximum color intensity for each of the three channels).\n",
        "# By dividing by the maximum value (or mutiplying by 1/255) we are scaling all the pixels value into a range between 0 and 1.\n",
        "# We also include a validation split: we can only split once for a given directory and we split the\n",
        "# train set into train and validation and we use a separate generator for the test set. \n",
        "train_gen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    validation_split=0.3\n",
        ")\n",
        "\n",
        "test_gen=tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale=1./255 # we do not include a validation split as mentioned before.\n",
        ")"
      ],
      "metadata": {
        "id": "gmM3kqCXT6eZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we flow from the dataframes\n",
        "train_data = train_gen.flow_from_dataframe(\n",
        "    train_df, # this is the dataframe were we are coming from\n",
        "    x_col=\"Filepath\",# which column used as a filepath and which column is used as a label\n",
        "    y_col=\"Label\",\n",
        "    target_size=(120, 120),\n",
        "    color_mode=\"rgb\", # three color channels\n",
        "    class_mode=\"categorical\", # in the case of multi-label classification the class_mode should be categorical (which is the default value). \"binary\" in case we have \"Positive\", \"Negative\" class for example.\n",
        "    batch_size=32, # standard\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    # resize the images as you want. TO DO: NEED TO CHECK WHAT WAS THE ORIGINAL SIZES OF THE IMAGES!!!\n",
        "    # CHIEDERE AL PROF UNA VOLTA RIASCOLTATE TUTTE LE LEZIONI COME PROCEDERE! LE IMMAGINI MI SEMBRAVA AVESSERO\n",
        "    # DIFFERENTI SIZES. DEVI PRIMA ESPLORARE IL DATASET PER POTERLO CAPIRE VERAMENTE!\n",
        "    # IMMAGINO DI DOVER USARE PRIMA OPENCV ALL'INIZIO PER DESCRIVERE IL DATASET CORRETTAMENTE.\n",
        "    # PASSAGGIO FONDAMENTALE DA FARE E NON DIMENTICARE COME FATTO NELLA TESI!!!\n",
        "    subset=\"training\" # when we pull from the train_gen and we specify \"training\" we get 0.8 reserved for training and if we specify \"validation\" we get the 0.2 percent \n",
        ")\n",
        "\n",
        "valid_data = train_gen.flow_from_dataframe(\n",
        "    train_df, # this is the dataframe were we are coming from\n",
        "    x_col=\"Filepath\",# which column used as a filepath and which column is used as a label\n",
        "    y_col=\"Label\",\n",
        "    target_size=(120, 120),\n",
        "    color_mode=\"rgb\", # three color channels\n",
        "    class_mode=\"categorical\", # in the case of multi-label classification the class_mode should be categorical (which is the default value). \"binary\" in case we have \"Positive\", \"Negative\" class for example.\n",
        "    batch_size=32, # standard\n",
        "    shuffle=True,\n",
        "    seed=42,\n",
        "    # resize the images as you want. TO DO: NEED TO CHECK WHAT WAS THE ORIGINAL SIZES OF THE IMAGES!!!\n",
        "    # CHIEDERE AL PROF UNA VOLTA RIASCOLTATE TUTTE LE LEZIONI COME PROCEDERE! LE IMMAGINI MI SEMBRAVA AVESSERO\n",
        "    # DIFFERENTI SIZES. DEVI PRIMA ESPLORARE IL DATASET PER POTERLO CAPIRE VERAMENTE!\n",
        "    # IMMAGINO DI DOVER USARE PRIMA OPENCV ALL'INIZIO PER DESCRIVERE IL DATASET CORRETTAMENTE.\n",
        "    # PASSAGGIO FONDAMENTALE DA FARE E NON DIMENTICARE COME FATTO NELLA TESI!!!\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "# we do not have to specify a subset for the test data\n",
        "test_data  = test_gen.flow_from_dataframe(\n",
        "    test_df,\n",
        "    x_col=\"Filepath\",# which column used as a filepath and which column is used as a label\n",
        "    y_col=\"Label\",\n",
        "    target_size=(120, 120),\n",
        "    color_mode=\"rgb\", # three color channels\n",
        "    class_mode=\"categorical\", # in the case of multi-label classification the class_mode should be categorical (which is the default value). \"binary\" in case we have \"Positive\", \"Negative\" class for example.\n",
        "    batch_size=32, # standard\n",
        "    shuffle=False, # we do not want to shuffle our test data, we encounter some problem otherwise evaluating the model. We want to mantain the model of the test sample because we want to compare them to the label in the end.\n",
        "    seed=42,\n",
        "    # resize the images as you want. TO DO: NEED TO CHECK WHAT WAS THE ORIGINAL SIZES OF THE IMAGES!!!\n",
        "    # CHIEDERE AL PROF UNA VOLTA RIASCOLTATE TUTTE LE LEZIONI COME PROCEDERE! LE IMMAGINI MI SEMBRAVA AVESSERO\n",
        "    # DIFFERENTI SIZES. DEVI PRIMA ESPLORARE IL DATASET PER POTERLO CAPIRE VERAMENTE!\n",
        "    # IMMAGINO DI DOVER USARE PRIMA OPENCV ALL'INIZIO PER DESCRIVERE IL DATASET CORRETTAMENTE.\n",
        "    # PASSAGGIO FONDAMENTALE DA FARE E NON DIMENTICARE COME FATTO NELLA TESI!!!\n",
        ")\n",
        "\n",
        "# The function goes through all the images and will count them as well.\n",
        "# First dataset:  train set\n",
        "# Second dataset: validation set\n",
        "# Third dataset:  test set"
      ],
      "metadata": {
        "id": "w9LiJBi2T6bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JAhGJE4kT6ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pmRcQPzdUN1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j6tXJqjkUNy2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GwFF3hEeUNwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "havgdvAZUNuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BdktAqv1UNsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wPzDtQ1HT6Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "-----------------------"
      ],
      "metadata": {
        "id": "3DHP2ERHT6VB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image(file_check):\n",
        "  img = image.load_img(file_check, target_size=(224, 224))\n",
        "  img_array = image.img_to_array(img)\n",
        "  img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "  return tf.keras.applications.mobilenet_v2.preprocess_input(img_array_expanded_dims)\n",
        "\n",
        "  # preprocess_input_mobilenetV2 = tf.keras.applications.mobilenet_v2.preprocess_input"
      ],
      "metadata": {
        "id": "llOd944x0YAT"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = list()\n",
        "\n",
        "imagepath1 = \"/content/crop_caesar1.jpg_RESIZED.jpg\"\n",
        "imagepath2 = \"/content/cropburger3.jpg_RESIZED.jpg\"\n",
        "imagepath3 = \"/content/cropfries4.jpg_RESIZED.jpg\"\n",
        "\n",
        "preprocessed_image1 = prepare_image(imagepath1)\n",
        "preprocessed_image2 = prepare_image(imagepath2)\n",
        "preprocessed_image3 = prepare_image(imagepath3)\n",
        "\n",
        "predictions1 = best_model.predict(preprocessed_image1)\n",
        "print(\"pred1\", predictions1[0])\n",
        "\n",
        "predictions2 = best_model.predict(preprocessed_image2)\n",
        "print(\"pred2\", predictions2[0])\n",
        "\n",
        "predictions3 = best_model.predict(preprocessed_image3)\n",
        "print(\"pred3\", predictions3[0])\n",
        "\n",
        "result.append(np.argmax(predictions1))\n",
        "result.append(np.argmax(predictions2))\n",
        "result.append(np.argmax(predictions3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "3a3GU43C0X77",
        "outputId": "40131b09-aae1-4121-d55e-b9b3a937e85c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6acfec5fca57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimagepath3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/cropfries4.jpg_RESIZED.jpg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpreprocessed_image1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagepath1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mpreprocessed_image2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagepath2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mpreprocessed_image3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimagepath3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-e873222a3a0a>\u001b[0m in \u001b[0;36mprepare_image\u001b[0;34m(file_check)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mprepare_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mimg_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mimg_array_expanded_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_array_expanded_dims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/image_utils.py\u001b[0m in \u001b[0;36mload_img\u001b[0;34m(path, grayscale, color_mode, target_size, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m       \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m       \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/crop_caesar1.jpg_RESIZED.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result # french fries, sushi, sushi"
      ],
      "metadata": {
        "id": "PB8JVmsP2OY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator_mnetv2.class_indices"
      ],
      "metadata": {
        "id": "Tbi01RZ22OWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "28r8GnrT2XW3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nr1H2exu2XSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Y6YVsb2m2XP6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Possible solutions\n",
        "\n",
        "- https://vijayabhaskar96.medium.com/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720\n",
        "\n",
        "- https://github.com/keras-team/keras/issues/14303"
      ],
      "metadata": {
        "id": "U8-nTMYs19PO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Wk03debi0X5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iQ0Ch3c-0X3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llllllllllllllllllllllllllllllll"
      ],
      "metadata": {
        "id": "11VInZ8ktpQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQDnrOigti_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HPyVF6Hati8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ezQKoRrEti6K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "My_DZqYHti32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t7fiCfebsusZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DWV-3eDJsuqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.applications.resnet50 import preprocess_input\n",
        "# from keras.applications.mobilenet_v2 import preprocess_input\n",
        "# from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "def prepare_image(file_input, show=True):\n",
        "    img = image.load_img(file_input, target_size=(SIZE, SIZE))\n",
        "    img_array = image.img_to_array(img)\n",
        "    # img_array_expanded_dims = preprocess_input(img_array)\n",
        "    # img_array= (img_array/255.0)\n",
        "    # img_array = img_array.astype(np.float32) / 255.0\n",
        "    # img_array = (img_array - 0.5) * 2\n",
        "    img_array_expanded_dims = np.expand_dims(img_array, axis=0)\n",
        "    # img_array_expanded_dims = preprocess_input(img_array_expanded_dims)\n",
        "\n",
        "    if show:\n",
        "      plt.imshow(img_array_expanded_dims[0])                           \n",
        "      plt.axis('off')\n",
        "      plt.show()\n",
        "\n",
        "    return img_array_expanded_dims\n",
        "\n",
        "    # return img_array_expanded_dims"
      ],
      "metadata": {
        "id": "_PGA0YQTBUW4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE A LIST TO STORE THE PATH OF EACH RANDOM IMAGE\n",
        "inference_data = list()\n",
        "\n",
        "# current_directory = Path(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset\")\n",
        "# current_directory = Path('/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/test/')\n",
        "current_directory = Path(base_path_test)\n",
        "# current_directory = Path('/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDatasetPreprocessed')\n",
        "\n",
        "for folder in current_directory.iterdir():\n",
        "  split_str = str(folder).split(\"/\")[-1] # get the folder name\n",
        "  print(split_str)\n",
        "  file_path_type = [f\"{current_directory}/{split_str}/*.jpg\"]  \n",
        "  # print(file_path_type)\n",
        "  images = glob.glob(random.choice(file_path_type))\n",
        "  # print(images)\n",
        "\n",
        "  for i in range(1):\n",
        "    # if len(inference_data) > 1:\n",
        "    #   break\n",
        "    random_image = random.choice(images)\n",
        "    # print(random_image)\n",
        "    inference_data.append(random_image)\n",
        "    # img_raw = cv2.imread(random_image)\n",
        "    print(inference_data)\n",
        "    print(\"------------\")"
      ],
      "metadata": {
        "id": "Fd-zNMRybLF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD SAVED MODEL AND GET PATH FOR AN IMAGE\n",
        "best_model = tf.keras.models.load_model(\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/saved_models/model_mobilenetV2.h5\") "
      ],
      "metadata": {
        "id": "sLMInDk_dCXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# im_test = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/test/hot_dog/20160711_1214411.jpg_RESIZED.jpg'"
      ],
      "metadata": {
        "id": "aeBCbKSWt2ro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# img = image.load_img(im_test, target_size=(224,224))\n",
        "# x = image.img_to_array(img)\n",
        "# x = np.expand_dims(x, axis=0)\n",
        "# x = preprocess_input(x)\n",
        "# print(full_model.predict(x))\n",
        "# plt.imshow(img)"
      ],
      "metadata": {
        "id": "-0_ADpe9t2n4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_output_list = list()\n",
        "ground_truth_list = list()\n",
        "ground_truth_dict = test_generator.class_indices\n",
        "\n",
        "for image_path in inference_data:\n",
        "  split_str = str(image_path).split(\"/\")[-2] # get the folder name\n",
        "  print(split_str)\n",
        "  new_image = prepare_image(image_path)\n",
        "  # print(new_image.shape)\n",
        "  pred = best_model.predict(new_image)\n",
        "\n",
        "  # Generate arg maxes for predictions\n",
        "  # output_index = np.argmax(pred[[0]], axis = 1)\n",
        "  output_index = np.argmax(pred, axis = 1)\n",
        "  print(\"Output index is:\", output_index)\n",
        "\n",
        "  pred_output_list.append(output_index[0])\n",
        "  ground_truth_list.append(ground_truth_dict[f'{split_str}'])\n",
        "\n",
        "  # if max(pred[0]) < 0.50:\n",
        "  #   print(\"I'm sorry, I cannot recognise any type of food here! Try again!\")\n",
        "  #   print(\"The groud truth is\", split_str)\n",
        "  # else:\n",
        "  #   value = [i for i in test_generator.class_indices if test_generator.class_indices[i]==np.argmax(pred, axis = 1)]\n",
        "  #   print(f\"The food in this image should be: {value[0]}.\")\n",
        "  #   print(\"The groud truth is\", split_str, \".\")\n",
        "  \n",
        "  print(\"\")\n",
        "  value = [i for i in test_generator.class_indices if test_generator.class_indices[i] == output_index]\n",
        "  print(f\"The food predicted is: {value[0]}.\")\n",
        "  print(\"------------------------ NEXT IMAGE ----------------------------\")\n",
        "  print(\"\")\n",
        "\n",
        "print(\"Predicted:\", pred_output_list)\n",
        "print(\"Ground Truth\", ground_truth_list)"
      ],
      "metadata": {
        "id": "plRJX9rdbLDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE A DATAFRAME TO COMPARE THE RESULTS\n",
        "df_comparison = pd.DataFrame({\"predicted\": pred_output_list, \"ground truth\": ground_truth_list})\n",
        "\n",
        "df_comparison['comparison'] = np.where(df_comparison['predicted'] == df_comparison['ground truth'], 1, \n",
        "                                      np.where(df_comparison['predicted'] !=  df_comparison['ground truth'], 0, -1))\n",
        "\n",
        "df_comparison"
      ],
      "metadata": {
        "id": "rGYDm99KbLB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MIGLIOR RISULTATO FINORA. POTREBBE ESSERE UN PROBLEMA DI INDICI???**"
      ],
      "metadata": {
        "id": "eholc0Q0bUUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# COMPUTE ACCURACY OVER THE TEN ELEMENTS\n",
        "accuracy_over_test = (np.sum(df_comparison['comparison'])/len(df_comparison))*100\n",
        "print(f\"Accuracy over {len(df_comparison)} images is:\", accuracy_over_test, \"%\")"
      ],
      "metadata": {
        "id": "p74SSlX1bK_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**SPECIFICARE CHE I BAD RESULTS SONO DATI DA SUSHI E SASHIMI**\n",
        "\n",
        "QUELLO CHE POTRESTI FARE E' PROVARE CON UN ALTRO DATASET FOOD E RIFARE LA STESSA COSA CON UN DATASET DIVERSO E MAGARE USARNE UN ALTRO ANCHE!"
      ],
      "metadata": {
        "id": "Ouepmldp6x8t"
      }
    }
  ]
}