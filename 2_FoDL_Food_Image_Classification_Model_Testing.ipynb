{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING NOTEBOOK"
      ],
      "metadata": {
        "id": "DZc9RWgg7sDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install packages"
      ],
      "metadata": {
        "id": "P2M0Vcnh7vlw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9WPhlhaKARRX"
      },
      "outputs": [],
      "source": [
        "!pip install scikeras\n",
        "!pip install split-folders # install the package to split the images in TRAIN and TEST folders\n",
        "!pip install ann_visualizer # visualize NN architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import libraries"
      ],
      "metadata": {
        "id": "o_R1GMku7qUg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT TENSORFLOW/KERAS\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
        "\n",
        "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input, decode_predictions\n",
        "\n",
        "from keras.layers import Input\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Flatten\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.pooling import GlobalMaxPooling2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# TRANSFER LEARNING\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50\n",
        "\n",
        "# SCIKIT-LEARN/SCIKERAS\n",
        "from sklearn import preprocessing\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import KFold\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "# IMPORT OTHER MODULES\n",
        "import os\n",
        "import glob\n",
        "import datetime\n",
        "\n",
        "import fnmatch # to count number of image per folder easily\n",
        "import random # to select random images from a folder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import splitfolders # needed to split the images in TRAIN and TEST folders\n",
        "from os import mkdir\n",
        "from pathlib import Path\n",
        "from shutil import copyfile # to import \"copyfile\"\n",
        "import plotly.figure_factory as ff # for printing the heatmap\n",
        "from collections import defaultdict\n",
        "from matplotlib import pyplot as plt\n",
        "import matplotlib.image as img_mat\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# CV2\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow "
      ],
      "metadata": {
        "id": "cASF6CV17qp4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SET RANDOM SEED TO GET, AS MUCH AS POSSIBLE, REPRODUCIBLE RESULTS\n",
        "# USING NUMPY\n",
        "from numpy.random import seed\n",
        "seed(42)\n",
        "\n",
        "# USING TENSORFLOW: IN ADDITION, TENSORFLOW HAS ITS OWN RANDOM NUMBER\n",
        "# GENERATOR THAT MUST ALSO BE SEEDED BY CALLING THE SET_RANDOM_SEED()\n",
        "# FUNCTION IMMEDIATELY AFTER THE NUMPY RANDOM NUMBER GENERATOR\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "CLfriD0E7yGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Link Google Drive account\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "id": "naK1Bu0m7zP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORT UTILS.PY\n",
        "\n",
        "# 1.Insert the directory\n",
        "import sys\n",
        "sys.path.insert(0,\"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food\")\n",
        "\n",
        "# 2.Import your module or file\n",
        "import utils"
      ],
      "metadata": {
        "id": "0KSt-frR70l2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CONSTANT\n",
        "# SCALE_PERCENT = 6 # resizing percentage\n",
        "SEED_VALUE = 42\n",
        "num_classes = 9 # number of output classes\n",
        "batch_size = 16\n",
        "SIZE = 96  #Resize images --> https://www.researchgate.net/post/Which_Image_resolution_should_I_use_for_training_for_deep_neural_network#:~:text=So%20the%20rule%20of%20thumb,for%20something%20smaller%20and%20easier.\n",
        "\n",
        "# PATH TO THE DATA\n",
        "ORIGINAL_DATA = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDataset\"\n",
        "PREPROCESSED_DATA = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/ExampleFoodImageDatasetPreprocessed\"\n",
        "DIR_TRAIN_TEST_DATA = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test' # path contenente i sottoinsiemi di train, test\n",
        "\n",
        "# LOAD THE FOLDERS WHERE THE TRAINING/TESTING/VALIDATION DATA ARE STORED\n",
        "base_path_train = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/'\n",
        "base_path_test = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/test/'\n",
        "base_path_val = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/'\n",
        "\n",
        "# PATH TO THE DATA\n",
        "DIR_TRAIN_DATA = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/train/*' # path contenente i sottoinsiemi di train, test\n",
        "DIR_TEST_DATA = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/test/*' # path contenente i sottoinsiemi di train, test\n",
        "DIR_VAL_DATA = '/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/*' # path contenente i sottoinsiemi di train, test"
      ],
      "metadata": {
        "id": "Q3CxQc1i72G8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SETTINGS FOR PRETTIER VISUALIZATION IN GOOGLE COLAB\n",
        "from IPython.display import Javascript\n",
        "def resize_colab_cell():\n",
        "  display(Javascript('google.colab.output.setIframeHeight(0, true, {maxHeight: 300})'))\n",
        "get_ipython().events.register('pre_run_cell', resize_colab_cell)"
      ],
      "metadata": {
        "id": "GoVaafJ873V1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Evaluate and Test on the test data - SPOSTARE QUESTA PARTE NELL'ULTIMO NOTEBOOK --> 2_FoDL_Food_Image_Classification_Model_Testing.ipynb"
      ],
      "metadata": {
        "id": "xL_fkXFG76ut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ricorda: devi aggiungere anche la classe \"No labels\" basandoti su un threshold e citando l'articolo che hai trovato a riferimento: se la probabilità più alta è minore del 50 o 60 % per esempio, allora l'immagine appartiene a nessuna classe! Fai anche dei test a proposito!"
      ],
      "metadata": {
        "id": "OhbTlq4778RS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For testing and validation dataset: https://galaxyinferno.com/what-is-validation-data-used-for-machine-learning-basics/#:~:text=A%20validation%20data%20set%20is,parameters%20within%20the%20model%20class."
      ],
      "metadata": {
        "id": "ds2ki7Bz7-LI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the best Model"
      ],
      "metadata": {
        "id": "ngdQC-vj7_1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD SAVED MODEL AND GET PATH FOR AN IMAGE\n",
        "best_model = load_model(\"mobilenetV2.h5\") "
      ],
      "metadata": {
        "id": "p5HjL4TI769R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# PREDICT USING THE BEST MODEL --> USE best_model INSTEAD OF model_mobilenetv2\n",
        "# Y_pred = model_mobilenetv2.predict(val_generator, val_generator.n // val_generator.batch_size)\n",
        "Y_pred = best_model.predict(val_generator, val_generator.n // val_generator.batch_size)\n",
        "\n",
        "val_preds = np.argmax(Y_pred, axis=1)\n",
        "val_trues = val_generator.classes\n",
        "print(val_trues)\n",
        "\n",
        "# PRINT THE CLASSIFICATION REPORT\n",
        "print(classification_report(val_trues, val_preds))"
      ],
      "metadata": {
        "id": "Se1yNul08CaM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Confusion Matrix**\n",
        "\n",
        "A confusion matrix is a table that is often used to describe the performance of a classification model (or “classifier”) on a set of test data for which the true values are known."
      ],
      "metadata": {
        "id": "vwZLO0IW8EEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Y_pred = model_mobilenetv2.predict(val_generator, val_generator.n // val_generator.batch_size)\n",
        "Y_pred = best_model.predict(val_generator, val_generator.n // val_generator.batch_size)\n",
        "\n",
        "val_preds = np.argmax(Y_pred, axis=1)\n",
        "val_trues = val_generator.classes\n",
        "\n",
        "# PRINT THE CONFUSION MATRIX\n",
        "cm = metrics.confusion_matrix(val_trues, val_preds)\n",
        "cm"
      ],
      "metadata": {
        "id": "TR4qOc8S8ES_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Create a heatmap as a confusion matrix"
      ],
      "metadata": {
        "id": "0erDy6HJ8Gno"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xx = ['caesar_salad', 'caprese_salad', 'french_fries', 'greek_salad', 'hamburger', 'hot_dog', 'pizza', 'sashimi', 'sushi']\n",
        "yy = ['caesar_salad', 'caprese_salad', 'french_fries', 'greek_salad', 'hamburger', 'hot_dog', 'pizza', 'sashimi', 'sushi']\n",
        "# yy = ['sushi', 'sashimi', 'pizza', 'hot_dog', 'hamburger', 'greek_salad', 'french_fries', 'caprese_salad', 'caesar_salad']"
      ],
      "metadata": {
        "id": "yUyGGodr8G5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# REFERENCES:\n",
        "# https://stackoverflow.com/questions/60860121/plotly-how-to-make-an-annotated-confusion-matrix-using-a-heatmap\n",
        "\n",
        "# change each element of z to type string for annotations\n",
        "z_text = [[str(yy) for y in xx] for x in cm]\n",
        "\n",
        "# set up figure \n",
        "fig = ff.create_annotated_heatmap(cm, x=xx, y=yy, colorscale='Viridis')\n",
        "\n",
        "# add title\n",
        "fig.update_layout(title_text='<i><b>Confusion matrix</b></i>',\n",
        "                  # xaxis = dict(title='x'),\n",
        "                  # yaxis = dict(title='x')\n",
        "                 )\n",
        "\n",
        "# add custom xaxis title\n",
        "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
        "                        x=0.5,\n",
        "                        y=-0.15,\n",
        "                        showarrow=False,\n",
        "                        text=\"Predicted value\",\n",
        "                        xref=\"paper\",\n",
        "                        yref=\"paper\"))\n",
        "\n",
        "# add custom yaxis title\n",
        "fig.add_annotation(dict(font=dict(color=\"black\",size=14),\n",
        "                        x=-0.15,\n",
        "                        y=0.5,\n",
        "                        showarrow=False,\n",
        "                        text=\"Real value\",\n",
        "                        textangle=-90,\n",
        "                        xref=\"paper\",\n",
        "                        yref=\"paper\"))\n",
        "\n",
        "# adjust margins to make room for yaxis title\n",
        "fig.update_layout(margin=dict(t=50, l=200))\n",
        "\n",
        "# add colorbar\n",
        "fig['data'][0]['showscale'] = True\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "EGIQl3XS8IwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GET A NEW IMAGE. IMPLEMENT THE SAME THING AS THE BOSCH PROJECT WHERE YOU HAD MULTIPLE RANDOM IMAGES\n",
        "\n",
        "caprese = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/caprese_salad/smaller_salad (14).jpg_RESIZED.jpg\"\n",
        "fries = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/french_fries/cropfries19.jpg_RESIZED.jpg\"\n",
        "greek_s = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/greek_salad/smaller_salad (29).jpg_RESIZED.jpg\"\n",
        "hamb = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/hamburger/cropburger26.jpg_RESIZED.jpg\"\n",
        "hotD = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/hot_dog/IMG_20160702_192206244.jpg_RESIZED.jpg\"\n",
        "pzz = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/pizza/crop_pizza26.jpg_RESIZED.jpg\"\n",
        "sash = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/sashimi/crop__sashimi9.jpg_RESIZED.jpg\"\n",
        "sush = \"/content/gdrive/MyDrive/Data_Science_2020-2022/Secondo_anno_Secondo_Semestre/FoDL_Project/Project_Example_Food/train_test/val/sushi/sushi_121.jpg_RESIZED.jpg\""
      ],
      "metadata": {
        "id": "xmTOO2EL8KkY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CREATE A LIST OF ALL THE PATH IMAGES\n",
        "food_path_list = [caprese,\n",
        "                  fries,\n",
        "                  greek_s,\n",
        "                  hamb,\n",
        "                  hotD,\n",
        "                  pzz,\n",
        "                  sash,\n",
        "                  sush]"
      ],
      "metadata": {
        "id": "hZeuajWp8Lp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load multiple images and predict\n",
        "\n",
        "This section has to be implemented inside the Deployment notebook."
      ],
      "metadata": {
        "id": "O3WW-cyt8NCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(img_path, show=True):\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
        "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
        "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
        "\n",
        "    if show:\n",
        "        plt.imshow(img_tensor[0])                           \n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "    return img_tensor\n",
        "  \n",
        "img_path = hotD\n",
        "new_image = load_image(img_path)\n",
        "\n",
        "pred = model_mobilenetv2.predict(new_image)\n",
        "# Generate arg maxes for predictions\n",
        "print(np.argmax(pred, axis = 1))\n",
        "\n",
        "pred"
      ],
      "metadata": {
        "id": "h6vV0yJf8PFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_generator.class_indices)"
      ],
      "metadata": {
        "id": "UnrRzynG8Qx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = best_model.predict(new_image)\n",
        "# Generate arg maxes for predictions\n",
        "print(np.argmax(pred_test, axis = 1))\n",
        "\n",
        "pred_test"
      ],
      "metadata": {
        "id": "zQFjAxMP8RtU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**QUI DOVRESTI AGGIUNGERE CHE, SE IL VALORE MASSIMO è AL DI SOTTO DEL 50% ALLORA LA PREDIZIONE NON è CORRETTA PER NULLA! E ALLORA SI HA LA \"NON CLASSE\". RIGUARDA PAPER CCHE TI ERI SALVATO ANCHE SU GITHUB E PROVA ANCHE CON ALTRE IMMAGINI CHE NON SONO CIBO!**"
      ],
      "metadata": {
        "id": "zHFSokZO8S3b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD MULTIPLE IMAGES\n",
        "# STILL TO TEST: DOVRESTI ANCHE OTTENERE DIRETTAMENTE L'IMMAGINE CON LA LABEL DI COSA CORRISPONDE!\n",
        "pred_output_list = [] # --> list()\n",
        "\n",
        "for images in food_path_list:\n",
        "  img_path = images\n",
        "  new_image = load_image(img_path)\n",
        "  pred = best_model.predict(new_image)\n",
        "  # Generate arg maxes for predictions\n",
        "  output_index = np.argmax(pred[[0]], axis = 1)\n",
        "  print(\"Output index is:\", output_index)\n",
        "\n",
        "  pred_output_list.append(output_index[0])\n",
        "\n",
        "print(pred_output_list)"
      ],
      "metadata": {
        "id": "ZZfDWEE78TKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "[1, 2, 8, 4, 5, 6, 4, 8]"
      ],
      "metadata": {
        "id": "A0a_A1Uy8Wj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_generator.class_indices)"
      ],
      "metadata": {
        "id": "4_cO883e8Xv4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# USA QUESTO LINK, UTILISSIMO PER LA PARTE DI PREDIZIONE!!!!\n",
        "\n",
        "https://stackoverflow.com/questions/43469281/how-to-predict-input-image-using-trained-model-in-keras"
      ],
      "metadata": {
        "id": "Nf7pFg8-8ZKY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10.Results Analysis"
      ],
      "metadata": {
        "id": "V2lWj4jl8bBV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11.Deploy in data app --> chek this out: \n",
        "- https://dev.to/code_jedi/how-to-turn-your-python-machine-learning-code-into-a-web-app-2hfc\n",
        "\n",
        "- https://towardsdatascience.com/how-to-deploy-machine-learning-models-601f8c13ff45\n",
        "\n",
        "- https://www.youtube.com/watch?v=xl0N7tHiwlw\n",
        "\n",
        "- https://towardsdatascience.com/how-to-build-an-image-classification-app-using-logistic-regression-with-a-neural-network-mindset-1e901c938355\n",
        "\n",
        "- https://analyticsindiamag.com/deploy-your-deep-learning-based-image-classification-model-with-streamlit/"
      ],
      "metadata": {
        "id": "x6XGRUWA8fSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 12.Future Work and Improvements"
      ],
      "metadata": {
        "id": "Ea-4jRkF8hCw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comments:\n",
        "\n",
        "\n",
        "*   Considera, nella parte finale, di aumentare le immagini ad almeno 1000 per classe (se non addirittura a 2000/3000)\n",
        "\n"
      ],
      "metadata": {
        "id": "nDAFiWI88iRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prova a cross validare con questo modello, vedi se ottieni risultati migliori!\n",
        "\n",
        "- https://stackoverflow.com/questions/62341053/validation-accuracy-not-improving"
      ],
      "metadata": {
        "id": "sIfKTrMS8kBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# RICORDATI: pip freeze to list the out the packages installed in your environment:"
      ],
      "metadata": {
        "id": "m4Bt3n5p8lpl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Follow this:\n",
        "- https://medium.com/@draj0718/image-classification-and-prediction-using-transfer-learning-3cf2c736589d\n",
        "\n",
        "- https://towardsdatascience.com/how-to-predict-an-image-with-keras-ca97d9cd4817\n",
        "\n",
        "- https://medium.com/@nutanbhogendrasharma/image-classification-with-resnet50-model-12f4c79c216b#:~:text=keras%2Fmodels%2F.,other%20to%20form%20a%20network."
      ],
      "metadata": {
        "id": "v2s9sW2p8nla"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UTILIZZA IL REPORT DI BOSCH COME BASE E DIRETTAMENTE L'OVERLEAF CREANDO UN PROGETTO IN LOCALE E CARICANDO SU GITHUB I RISULTATI INTERMEDI E COMPLETI!"
      ],
      "metadata": {
        "id": "gkp32BJ_8p0z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Check this for explanation of dimension and for explanation of each layer CNN:\n",
        "\n",
        "- https://towardsdatascience.com/image-classification-with-convolutional-neural-networks-12a7b4fb4c91\n",
        "- https://stackoverflow.com/questions/45561306/understanding-model-summary-keras\n",
        "- https://iq.opengenus.org/output-size-of-convolution/#:~:text=Machine%20Learning%20(ML)%20cnn&text=In%20short%2C%20the%20answer%20is,%2F%20(stride%20width)%20%2B%201\n",
        "\n",
        "# Visualization CNN:\n",
        "\n",
        "- https://netron.app/\n",
        "- https://towardsdatascience.com/how-to-visualize-neural-network-architectures-in-python-567cd2aa6d62\n",
        "- http://alexlenail.me/NN-SVG/LeNet.html\n",
        "- https://datascience.stackexchange.com/questions/12851/how-do-you-visualize-neural-network-architectures\n",
        "\n",
        "# For the report:\n",
        "\n",
        "- https://pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/\n",
        "\n",
        "Types of creation of a model in keras\n",
        "- https://pyimagesearch.com/2019/10/28/3-ways-to-create-a-keras-model-with-tensorflow-2-0-sequential-functional-and-model-subclassing/\n"
      ],
      "metadata": {
        "id": "cDNbrQCR8tBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "USE THIS:\n",
        "CONVERT IMAGEDATAGENERATOR AS NUMPY ARRAY AND FEED THEM INSIDE GRIDSEARCHCV AS X AND Y:\n",
        "- https://stackoverflow.com/questions/42284873/assign-imagedatagenerator-result-to-numpy-array\n",
        "\n",
        "FOLLOWING THEN:\n",
        "- https://machinelearningmastery.com/grid-search-hyperparameters-deep-learning-models-python-keras/\n",
        "\n",
        "\n",
        "CHECK:\n",
        "- https://stackoverflow.com/questions/47279677/how-use-grid-search-with-fit-generator-in-keras\n",
        "- https://stackoverflow.com/questions/59023969/grid-search-hyperparameters-for-an-image-classification-model\n",
        "- https://stackoverflow.com/questions/54078455/grid-search-with-gridsearchcv-scikit-learn-hyperparameter-tuning-using-image\n",
        "\n",
        "CONVERT IMAGES TO ARRAYS\n",
        "- https://www.quora.com/How-do-I-load-train-and-test-data-from-the-local-drive-for-a-deep-learning-Keras-model"
      ],
      "metadata": {
        "id": "kzCSBPlI8vhO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cerca online anche altre architetture di CNN differenti e aumenta deepness dell'architettura per arrivare almeno a 10 layers!\n",
        "\n",
        "- https://towardsdatascience.com/image-classification-with-convolutional-neural-networks-12a7b4fb4c91\n",
        "\n",
        "Altro tipo di architettura:\n",
        "- https://www.kdnuggets.com/2022/05/image-classification-convolutional-neural-networks-cnns.html\n",
        "\n",
        "Try:\n",
        "\n",
        "- https://medium.com/codex/how-to-tune-hyperparameters-for-better-neural-network-performance-b8f542855d2e\n",
        "- https://towardsdatascience.com/increase-the-accuracy-of-your-cnn-by-following-these-5-tips-i-learned-from-the-kaggle-community-27227ad39554\n",
        "- https://medium.com/@navmcgill/k-fold-cross-validation-in-keras-convolutional-neural-networks-835bed559d04\n",
        "\n",
        "Instead of Max pooling, you can also use fractional pooling:\n",
        "\n",
        "https://stackoverflow.com/questions/44991470/using-tensorflow-layers-in-keras\n",
        "\n",
        "Check the paper:\n",
        "Efficient Processing DNN a tutorial and survery, page 10 for reference."
      ],
      "metadata": {
        "id": "OdVHmR8b8xqP"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3XQUzikC8bcT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}